{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "60942e6c516a29541a1535264ae517a7",
          "grade": false,
          "grade_id": "cell-f17628a8eca2cbc0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "C2KDbuAh-Olm"
      },
      "source": [
        "# Logistic Regression Checkpoint\n",
        "\n",
        "This checkpoint is designed to test your understanding of the content from the Logistic Regression Cumulative Lab.\n",
        "\n",
        "Specifically, this will cover:\n",
        "\n",
        "* Calculating and interpreting classification metrics, particularly in the context of class imbalance\n",
        "* Performing an end-to-end ML process with logistic regression\n",
        "* Using NumPy and not pandas in a modeling context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d15bc418eb3f8a9ad3482c52a1ad2abe",
          "grade": false,
          "grade_id": "cell-f2bd8816c42b2fb1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xtpAxaFR-Olw"
      },
      "source": [
        "## Your Task: Use Logistic Regression on the Wisconsin Breast Cancer Dataset\n",
        "\n",
        "### Data Understanding\n",
        "\n",
        "Here we will use the Wisconsin Breast Cancer dataset, which is available through scikit-learn ([documentation here](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)).  The goal is to predict whether a breast mass is benign or malignant based on attributes of cell nuclei in a tissue sample. Deeper understanding of the specific attributes is not required for this task.\n",
        "\n",
        "In the cell below, we load this dataset, perform a train-test split, and scale the data for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cbc515aa796d463c33631678814267f8",
          "grade": false,
          "grade_id": "cell-5acfbd990f38a8e8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_dupGe6v-Olz"
      },
      "outputs": [],
      "source": [
        "# Run this cell without changes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('breast_cancer.csv')\n",
        "# Seperate features from target\n",
        "X, y = df.iloc[:,:-1].to_numpy(), df.iloc[:,-1].to_numpy()\n",
        "# Perform train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "# Scale data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bc17cd48c3bea078d27a994ecbf57d9c",
          "grade": false,
          "grade_id": "cell-900fc5185c49d611",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wfzBFj5Z-Ol2"
      },
      "source": [
        "### 1. Baseline Metrics\n",
        "\n",
        "Before we actually perform any modeling, let's determine what metrics we would expect to get with a \"dummy\" model that always predicts the positive class.\n",
        "\n",
        "For this assessment we'll define \"negative\" as a 0 (benign) and \"positive\" as a 1 (malignant).\n",
        "\n",
        "We will focus on the test data, since this is what we will use to evaluate our actual model as well.\n",
        "\n",
        "The code below shows an array containing the number of records in the test dataset with class 0 (benign) and class 1 (malignant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cf4fcd118e4c575b8889bd33e80dcf71",
          "grade": false,
          "grade_id": "cell-3749265b38571fac",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "bEibxe0J-Ol2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e6ffd5-94a7-42b1-e224-bb5f42bf63f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([89, 54])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Run this cell without changes\n",
        "np.bincount(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f631342e2d949cc02de4778a61da6a7b",
          "grade": false,
          "grade_id": "cell-a235418dd6df809c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "10kAGMfq-Ol3"
      },
      "source": [
        "In other words, a model that always predicts the positive class, will predict a 1 for every observation. Given the imbalance of the target seen above, (The balance is similar in the training data as well), we will calculate different classification metrics to evaluate the model's performance for both positive and negative labels.\n",
        "\n",
        "The confusion matrix looks like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ff5c3cef4fcd679c2ec6ac7a0e7ef3fa",
          "grade": false,
          "grade_id": "cell-f5e5c157e227ff7e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cE1YPfHv-Ol4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "c301de6b-9f28-4690-d7ed-41cfa0155e72"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAGwCAYAAABSAee3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0jklEQVR4nO3de1iUdf7/8deAMKAwo3gASTBK81CesjLKsowia01XdzusbWRW3wotZa302tQ0jbJvaRZqB8Pcb64dddM2W6PNQ6klZb8ORh4oKAV1DRBcDs7cvz/I2Z3UmmFmmBnu5+O67mubz9yHN3tx+eb9/nzu+7YYhmEIAACEpYhgBwAAAJqORA4AQBgjkQMAEMZI5AAAhDESOQAAYYxEDgBAGCORAwAQxloFOwBfOJ1O7d27V/Hx8bJYLMEOBwDgJcMwdPjwYSUnJysiInC1ZW1trerr630+T3R0tGJiYvwQkf+EdSLfu3evUlJSgh0GAMBHpaWl6tKlS0DOXVtbq7SucSrb7/D5XElJSSouLg6pZB7WiTw+Pl6SNFhXqZWighwNEBgrv/k82CEAAVNV7VTXs791/XseCPX19Srb79B3hafKFt/0qr/qsFNdB36r+vp6Erm/HGunt1KUWllI5GiZfPmHBwgXzTE9GhdvUVx806/jVGhO4YZ1IgcAwFMOwymHD28XcRhO/wXjRyRyAIApOGXIqaZncl+ODSR6dgAAhDEqcgCAKTjllC/Ncd+ODhwSOQDAFByGIYfR9Pa4L8cGEq11AADCGBU5AMAUWupiNxI5AMAUnDLkaIGJnNY6AABhjIocAGAKtNYBAAhjrFoHAAAhh4ocAGAKzp82X44PRSRyAIApOHxcte7LsYFEIgcAmILDkI9vP/NfLP7EHDkAAGGMihwAYArMkQMAEMacssghi0/HhyJa6wAAhDEqcgCAKTiNxs2X40MRiRwAYAoOH1vrvhwbSLTWAQAIY1TkAABTaKkVOYkcAGAKTsMip+HDqnUfjg0kWusAAIQxKnIAgCnQWgcAIIw5FCGHD41ohx9j8ScSOQDAFAwf58gN5sgBAIC/UZEDAEyBOXIAAMKYw4iQw/BhjjxEH9FKax0AgABwOByaNm2a0tLSFBsbq9NPP10PPfSQDOM/fxEYhqHp06erc+fOio2NVUZGhnbu3OnVdUjkAABTcMoipyJ82LxrrT/66KNatGiRnn76ae3YsUOPPvqo5s6dq6eeesq1z9y5c7VgwQItXrxYW7duVZs2bZSZmana2lqPr0NrHQBgCv6aI6+qqnIbt1qtslqtx+3/4YcfasSIEbr66qslSaeeeqr++te/6qOPPpLUWI3Pnz9fDzzwgEaMGCFJWrZsmRITE7Vq1Spdf/31HsVFRQ4AgBdSUlJkt9tdW25u7gn3u+CCC1RQUKBvvvlGkvTZZ59p06ZNGjZsmCSpuLhYZWVlysjIcB1jt9s1aNAgbd682eN4qMgBAKbg+2K3xrnt0tJS2Ww21/iJqnFJmjJliqqqqtSzZ09FRkbK4XBozpw5GjNmjCSprKxMkpSYmOh2XGJious7T5DIAQCm0DhH7sNLU3461mazuSXyk3nllVf00ksvafny5TrzzDO1fft2TZw4UcnJycrKympyHD9HIgcAIADuvfdeTZkyxTXX3adPH3333XfKzc1VVlaWkpKSJEnl5eXq3Lmz67jy8nL179/f4+swRw4AMAXnT89ab+rm9DJlHjlyRBER7sdERkbK6XRKktLS0pSUlKSCggLX91VVVdq6davS09M9vg4VOQDAFPw1R+6p4cOHa86cOUpNTdWZZ56pTz/9VE888YRuueUWSZLFYtHEiRM1e/Zsde/eXWlpaZo2bZqSk5M1cuRIj69DIgcAmIKzCVW1+/HeJfKnnnpK06ZN01133aX9+/crOTlZ//M//6Pp06e79rnvvvtUU1Oj22+/XRUVFRo8eLDWrl2rmJgYj69jMQwv/8QIIVVVVbLb7bpEI9TKEhXscICAeGfv9mCHAARM1WGn2p2xR5WVlR4tIGvSNX7KFcu3n6XW8ZFNPs+Rww79of8XAY21KajIAQCm4DAscvjwKlJfjg0kEjkAwBSOLVpr+vGh2cBm1ToAAGGMihwAYApOI0JOH1atO0N0SRmJHABgCrTWAQBAyKEiBwCYglO+rTx3+i8UvyKRAwBMwfcHwoRmEzs0owIAAB6hIgcAmILvz1oPzdqXRA4AMAV/vY881JDIAQCm0FIr8tCMCgAAeISKHABgCr4/ECY0a18SOQDAFJyGRU5f7iMP0befheafFwAAwCNU5AAAU3D62FoP1QfCkMgBAKbg+9vPQjORh2ZUAADAI1TkAABTcMgihw8PdfHl2EAikQMATIHWOgAACDlU5AAAU3DIt/a4w3+h+BWJHABgCi21tU4iBwCYAi9NAQAAIYeKHABgCoaP7yM3uP0MAIDgobUOAABCDhU5AMAUeI0pAABhzPHT28982bxx6qmnymKxHLdlZ2dLkmpra5Wdna327dsrLi5Oo0ePVnl5udc/F4kcAIAA+Pjjj7Vv3z7Xtm7dOknS73//e0nSpEmTtHr1ar366qtav3699u7dq1GjRnl9HVrrAABTaO7WeseOHd0+P/LIIzr99NM1ZMgQVVZWasmSJVq+fLmGDh0qScrPz1evXr20ZcsWnX/++R5fh4ocAGAKTkX4vElSVVWV21ZXV/er166vr9f//d//6ZZbbpHFYlFhYaEaGhqUkZHh2qdnz55KTU3V5s2bvfq5SOQAAHghJSVFdrvdteXm5v7qMatWrVJFRYVuvvlmSVJZWZmio6PVtm1bt/0SExNVVlbmVTy01gEApuAwLHL40Fo/dmxpaalsNptr3Gq1/uqxS5Ys0bBhw5ScnNzk658MiRwAYAr+miO32WxuifzXfPfdd3r33Xf1xhtvuMaSkpJUX1+viooKt6q8vLxcSUlJXsVFax0AYArGT28/a+pmNPHJbvn5+erUqZOuvvpq19jAgQMVFRWlgoIC11hRUZFKSkqUnp7u1fmpyAEACBCn06n8/HxlZWWpVav/pFy73a5x48YpJydHCQkJstlsmjBhgtLT071asS6RyAEAJuGQRQ4fXnzSlGPfffddlZSU6JZbbjnuu3nz5ikiIkKjR49WXV2dMjMztXDhQq+vQSIHAJiC0/DtMatOw/tjrrjiChnGiQ+MiYlRXl6e8vLymhyTxBw5AABhjYocHht+80H97s79Suh4VHu+itXCB05R0fbWwQ4L8IrDIf3f40kqeL2dfjwQpfaJDbr82kP6w8RyWX4q1n480EpL5iSrcH28aiojddb51cqe/b1OOa0+uMHDJ8cWrflyfCgKzagQcoZc86Nun7FXLz2RpOzMM7TnqxjNWb5H9vYNwQ4N8MoreZ205sUOyp7zg55b/7XG/XmvXl3YSX9b0kGSZBjSzFvStO+7aD2Yv0d5/yhSYpd6Tbmum2qP8E9mOHPK4vMWikLitzIvL0+nnnqqYmJiNGjQIH300UfBDgk/M+r2g1q7PEH/eDlBJTtjtOD+Lqr7t0WZNxwKdmiAV77a1kbpmZUalFGlpJR6XfSbSp095LCru/TDHqt2FLbRhEe+V4/+/1ZKtzpNeOR71dVa9M+VbYMbPHACQU/kL7/8snJycjRjxgx98skn6tevnzIzM7V///5gh4aftIpyqnvfI/pkY7xrzDAs+nRjvHoPPBLEyADv9T6nRts3xev73Y1P49r9ZYy+/KiNzh16WJLUUN9YdUVbna5jIiKkqGhDX34c1/wBw2+OPdnNly0UBT2RP/HEE7rttts0duxY9e7dW4sXL1br1q31wgsvBDs0/MSW4FBkK6nigPuSih8PtlK7jkeDFBXQNNeN368hI37UrRf31FWp/ZR9RQ/99rYDGjrqR0lSSrdadTqlXi/kdtbhikg11Fv08tOddHBftA6Vs6wonPnyMBhf59cDKai/lfX19SosLNTUqVNdYxEREcrIyDjh21/q6urc3jJTVVXVLHECaDk2vNlW773RTlPyvlPXHrXa/WWsFs845adFbz+qVZQ0fUmxnshJ1e9691FEpKEBFx3WuUOrdJK7iICgCmoiP3jwoBwOhxITE93GExMT9fXXXx+3f25urmbOnNlc4eEnVYci5Tgqtf1Z9d2uw1H9eIAKBeHluYeSdd34/bpkZIUkKa1XrfZ/H60VTyXq8msbq/Luff+tRe8WqaYqQg0NFrVt79DdV3fXGX2ZSgpnTvn4rHUWu/lu6tSpqqysdG2lpaXBDskUjjZEaOf/a60Bgw+7xiwWQ/0HV+urQm4/Q3ipq42QJcK9tI6INE5YbbexOdW2vUM/7InWzs9aKz2TLmA4M3xcsW6EaCIPajnVoUMHRUZGqry83G38ZG9/sVqtHr0uDv73xrMdNHl+qb75rLWKPm2t3952QDGtnfrHioRghwZ45fzLq7RiQaI6ndLQ2Fr/IlZvPNNJV1z/L9c+G1bbZW/vUKdT6lW8I0aLp3dR+pWVGnjJ4V84M0Kdv95+FmqCmsijo6M1cOBAFRQUaOTIkZIaHzBfUFCg8ePHBzM0/Mz6N9vJ3t6hm+4tU7uOR7Xny1j9eUyaKg5GBTs0wCt3zf5eL87trKendlHFv1qpfWKDrvrjQY2Z9J+C4lB5lJ558BRVHGylhE5HlfH7xgfGAKEo6BOcOTk5ysrK0jnnnKPzzjtP8+fPV01NjcaOHRvs0PAzb+Z30Jv5HYIdBuCT1nFO3TnrB90564eT7jPy1oMaeevBZowKzaGlPtkt6In8uuuu04EDBzR9+nSVlZWpf//+Wrt27XEL4AAA8AWt9QAaP348rXQAAJogJBI5AACB5uvz0kP19jMSOQDAFFpqaz00Z+4BAIBHqMgBAKbQUityEjkAwBRaaiKntQ4AQBijIgcAmEJLrchJ5AAAUzDk2y1kofoWWxI5AMAUWmpFzhw5AABhjIocAGAKLbUiJ5EDAEyhpSZyWusAAIQxKnIAgCm01IqcRA4AMAXDsMjwIRn7cmwg0VoHACCMUZEDAEyhpb6PnIocAGAKx+bIfdm89cMPP+jGG29U+/btFRsbqz59+mjbtm2u7w3D0PTp09W5c2fFxsYqIyNDO3fu9OoaJHIAAALgxx9/1IUXXqioqCi9/fbb+uqrr/T444+rXbt2rn3mzp2rBQsWaPHixdq6davatGmjzMxM1dbWenwdWusAAFNo7sVujz76qFJSUpSfn+8aS0tL+6/zGZo/f74eeOABjRgxQpK0bNkyJSYmatWqVbr++us9ug4VOQDAFPzVWq+qqnLb6urqTni9N998U+ecc45+//vfq1OnThowYICee+451/fFxcUqKytTRkaGa8xut2vQoEHavHmzxz8XiRwAYArHKnJfNklKSUmR3W53bbm5uSe83p49e7Ro0SJ1795d77zzju68807dfffdevHFFyVJZWVlkqTExES34xITE13feYLWOgAAXigtLZXNZnN9tlqtJ9zP6XTqnHPO0cMPPyxJGjBggL744gstXrxYWVlZfouHihwAYAqGj231YxW5zWZz206WyDt37qzevXu7jfXq1UslJSWSpKSkJElSeXm52z7l5eWu7zxBIgcAmIIhyTB82Ly83oUXXqiioiK3sW+++UZdu3aV1LjwLSkpSQUFBa7vq6qqtHXrVqWnp3t8HVrrAAAEwKRJk3TBBRfo4Ycf1rXXXquPPvpIzz77rJ599llJksVi0cSJEzV79mx1795daWlpmjZtmpKTkzVy5EiPr0MiBwCYglMWWZrxyW7nnnuuVq5cqalTp2rWrFlKS0vT/PnzNWbMGNc+9913n2pqanT77beroqJCgwcP1tq1axUTE+PxdUjkAABTCMZLU37zm9/oN7/5zUm/t1gsmjVrlmbNmtXkuJgjBwAgjFGRAwBMwWlYZOF95AAAhKdjq899OT4U0VoHACCMUZEDAEwhGIvdmgOJHABgCiRyAADCWEtd7MYcOQAAYYyKHABgCi111TqJHABgCo2J3Jc5cj8G40e01gEACGNU5AAAU2DVOgAAYcyQ9+8U//nxoYjWOgAAYYyKHABgCrTWAQAIZy20t04iBwCYg48VuUK0ImeOHACAMEZFDgAwBZ7sBgBAGGupi91orQMAEMaoyAEA5mBYfFuwFqIVOYkcAGAKLXWOnNY6AABhjIocAGAOPBAGAIDw1VJXrXuUyN98802PT3jNNdc0ORgAAOAdjxL5yJEjPTqZxWKRw+HwJR4AAAInRNvjvvAokTudzkDHAQBAQLXU1rpPq9Zra2v9FQcAAIFl+GELQV4ncofDoYceekinnHKK4uLitGfPHknStGnTtGTJEr8HCABAOHrwwQdlsVjctp49e7q+r62tVXZ2ttq3b6+4uDiNHj1a5eXlXl/H60Q+Z84cLV26VHPnzlV0dLRr/KyzztLzzz/vdQAAADQPix8275x55pnat2+fa9u0aZPru0mTJmn16tV69dVXtX79eu3du1ejRo3y+hpe3362bNkyPfvss7rssst0xx13uMb79eunr7/+2usAAABoFkG4j7xVq1ZKSko6bryyslJLlizR8uXLNXToUElSfn6+evXqpS1btuj888/3+BpeV+Q//PCDunXrdty40+lUQ0ODt6cDACCsVFVVuW11dXUn3Xfnzp1KTk7WaaedpjFjxqikpESSVFhYqIaGBmVkZLj27dmzp1JTU7V582av4vE6kffu3VsbN248bvy1117TgAEDvD0dAADNw0+L3VJSUmS3211bbm7uCS83aNAgLV26VGvXrtWiRYtUXFysiy66SIcPH1ZZWZmio6PVtm1bt2MSExNVVlbm1Y/ldWt9+vTpysrK0g8//CCn06k33nhDRUVFWrZsmdasWePt6QAAaB5+evtZaWmpbDaba9hqtZ5w92HDhrn+u2/fvho0aJC6du2qV155RbGxsU2P42e8rshHjBih1atX691331WbNm00ffp07dixQ6tXr9bll1/ut8AAAAhFNpvNbTtZIv+5tm3b6owzztCuXbuUlJSk+vp6VVRUuO1TXl5+wjn1X9KkZ61fdNFFWrduXVMOBQAgKIL9GtPq6mrt3r1bf/zjHzVw4EBFRUWpoKBAo0ePliQVFRWppKRE6enpXp23yS9N2bZtm3bs2CGpcd584MCBTT0VAACB18yr1idPnqzhw4era9eu2rt3r2bMmKHIyEjdcMMNstvtGjdunHJycpSQkCCbzaYJEyYoPT3dqxXrUhMS+ffff68bbrhBH3zwgWuSvqKiQhdccIFWrFihLl26eHtKAABanGP58l//+pc6duyowYMHa8uWLerYsaMkad68eYqIiNDo0aNVV1enzMxMLVy40OvreJ3Ib731VjU0NGjHjh3q0aOHpMZ2wNixY3Xrrbdq7dq1XgcBAEDA+Wmxm6dWrFjxi9/HxMQoLy9PeXl5TY9JTUjk69ev14cffuhK4pLUo0cPPfXUU7rooot8CgYAgECxGI2bL8eHIq8TeUpKygkf/OJwOJScnOyXoAAA8LsgPNmtOXh9+9ljjz2mCRMmaNu2ba6xbdu26Z577tH//u//+jU4AADwyzyqyNu1ayeL5T9zAzU1NRo0aJBatWo8/OjRo2rVqpVuueUWjRw5MiCBAgDgk2aeI28uHiXy+fPnBzgMAAACrIW21j1K5FlZWYGOAwAANEGTHwgjNb4Uvb6+3m3sv58/CwBAyGihFbnXi91qamo0fvx4derUSW3atFG7du3cNgAAQpKf3n4WarxO5Pfdd5/ee+89LVq0SFarVc8//7xmzpyp5ORkLVu2LBAxAgCAk/C6tb569WotW7ZMl1xyicaOHauLLrpI3bp1U9euXfXSSy9pzJgxgYgTAADftNBV615X5IcOHdJpp50mqXE+/NChQ5KkwYMHa8OGDf6NDgAAPzn2ZDdftlDkdSI/7bTTVFxcLEnq2bOnXnnlFUmNlfqxl6gAAIDm4XUiHzt2rD777DNJ0pQpU5SXl6eYmBhNmjRJ9957r98DBADAL1roYjev58gnTZrk+u+MjAx9/fXXKiwsVLdu3dS3b1+/BgcAAH6ZT/eRS1LXrl3VtWtXf8QCAEDAWOTj28/8Fol/eZTIFyxY4PEJ77777iYHAwAAvONRIp83b55HJ7NYLCRywM/O2HBTsEMAAsZ5pFbSw81zsRZ6+5lHifzYKnUAAMIWj2gFAAChxufFbgAAhIUWWpGTyAEApuDr09lazJPdAABA6KAiBwCYQwttrTepIt+4caNuvPFGpaen64cffpAk/eUvf9GmTZv8GhwAAH7TQh/R6nUif/3115WZmanY2Fh9+umnqqurkyRVVlbq4Yeb6V5AAAAgqQmJfPbs2Vq8eLGee+45RUVFucYvvPBCffLJJ34NDgAAf2mprzH1eo68qKhIF1988XHjdrtdFRUV/ogJAAD/a6FPdvO6Ik9KStKuXbuOG9+0aZNOO+00vwQFAIDfMUfe6LbbbtM999yjrVu3ymKxaO/evXrppZc0efJk3XnnnYGIEQAAnITXrfUpU6bI6XTqsssu05EjR3TxxRfLarVq8uTJmjBhQiBiBADAZy31gTBeJ3KLxaI///nPuvfee7Vr1y5VV1erd+/eiouLC0R8AAD4B/eRu4uOjlbv3r113nnnkcQBAPgFjzzyiCwWiyZOnOgaq62tVXZ2ttq3b6+4uDiNHj1a5eXlXp/b64r80ksvlcVy8pV77733ntdBAAAQcL7eQtbEYz/++GM988wz6tu3r9v4pEmT9NZbb+nVV1+V3W7X+PHjNWrUKH3wwQdend/rRN6/f3+3zw0NDdq+fbu++OILZWVleXs6AACaRxBa69XV1RozZoyee+45zZ492zVeWVmpJUuWaPny5Ro6dKgkKT8/X7169dKWLVt0/vnne3wNrxP5vHnzTjj+4IMPqrq62tvTAQAQVqqqqtw+W61WWa3WE+6bnZ2tq6++WhkZGW6JvLCwUA0NDcrIyHCN9ezZU6mpqdq8ebNXidxvbz+78cYb9cILL/jrdAAA+Jef7iNPSUmR3W53bbm5uSe83IoVK/TJJ5+c8PuysjJFR0erbdu2buOJiYkqKyvz6sfy29vPNm/erJiYGH+dDgAAv/LX7WelpaWy2Wyu8RNV46Wlpbrnnnu0bt26gOdGrxP5qFGj3D4bhqF9+/Zp27ZtmjZtmt8CAwAgFNlsNrdEfiKFhYXav3+/zj77bNeYw+HQhg0b9PTTT+udd95RfX29Kioq3Kry8vJyJSUleRWP14ncbre7fY6IiFCPHj00a9YsXXHFFd6eDgCAFueyyy7T559/7jY2duxY9ezZU/fff79SUlIUFRWlgoICjR49WlLju0xKSkqUnp7u1bW8SuQOh0Njx45Vnz591K5dO68uBABAUDXjqvX4+HidddZZbmNt2rRR+/btXePjxo1TTk6OEhISZLPZNGHCBKWnp3u10E3yMpFHRkbqiiuu0I4dO0jkAICwEmqPaJ03b54iIiI0evRo1dXVKTMzUwsXLvT6PF631s866yzt2bNHaWlpXl8MAACzev/9990+x8TEKC8vT3l5eT6d1+vbz2bPnq3JkydrzZo12rdvn6qqqtw2AABCVgt7hankRUU+a9Ys/elPf9JVV10lSbrmmmvcHtVqGIYsFoscDof/owQAwFct9KUpHifymTNn6o477tA///nPQMYDAAC84HEiN4zGP0WGDBkSsGAAAAiUUFvs5i9eLXb7pbeeAQAQ0szeWpekM84441eT+aFDh3wKCAAAeM6rRD5z5szjnuwGAEA4oLUu6frrr1enTp0CFQsAAIHTQlvrHt9Hzvw4AAChx+tV6wAAhKUWWpF7nMidTmcg4wAAIKCYIwcAIJy10Irc62etAwCA0EFFDgAwhxZakZPIAQCm0FLnyGmtAwAQxqjIAQDmQGsdAIDwRWsdAACEHCpyAIA50FoHACCMtdBETmsdAIAwRkUOADAFy0+bL8eHIhI5AMAcWmhrnUQOADAFbj8DAAAhh4ocAGAOtNYBAAhzIZqMfUFrHQCAMEZFDgAwhZa62I1EDgAwhxY6R05rHQCAAFi0aJH69u0rm80mm82m9PR0vf32267va2trlZ2drfbt2ysuLk6jR49WeXm519chkQMATOFYa92XzRtdunTRI488osLCQm3btk1Dhw7ViBEj9OWXX0qSJk2apNWrV+vVV1/V+vXrtXfvXo0aNcrrn4vWOgDAHPzUWq+qqnIbtlqtslqtx+0+fPhwt89z5szRokWLtGXLFnXp0kVLlizR8uXLNXToUElSfn6+evXqpS1btuj888/3OCwqcgAAvJCSkiK73e7acnNzf/UYh8OhFStWqKamRunp6SosLFRDQ4MyMjJc+/Ts2VOpqanavHmzV/FQkQMATMFfq9ZLS0tls9lc4yeqxo/5/PPPlZ6ertraWsXFxWnlypXq3bu3tm/frujoaLVt29Zt/8TERJWVlXkVF4kcAGAOfmqtH1u85okePXpo+/btqqys1GuvvaasrCytX7/ehyCORyIHAJhDEG4/i46OVrdu3SRJAwcO1Mcff6wnn3xS1113nerr61VRUeFWlZeXlyspKcmrazBHDgBAM3E6naqrq9PAgQMVFRWlgoIC13dFRUUqKSlRenq6V+ekIgcAmEJzP9lt6tSpGjZsmFJTU3X48GEtX75c77//vt555x3Z7XaNGzdOOTk5SkhIkM1m04QJE5Senu7VinWJRA4AMItmbq3v379fN910k/bt2ye73a6+ffvqnXfe0eWXXy5JmjdvniIiIjR69GjV1dUpMzNTCxcu9DosEjkAAAGwZMmSX/w+JiZGeXl5ysvL8+k6JHIAgClYDEMWo+kluS/HBhKJHABgDrw0BQAAhBoqcgCAKfA+cgAAwhmtdQAAEGqoyAEApkBrHQCAcNZCW+skcgCAKbTUipw5cgAAwhgVOQDAHGitAwAQ3kK1Pe4LWusAAIQxKnIAgDkYRuPmy/EhiEQOADAFVq0DAICQQ0UOADAHVq0DABC+LM7GzZfjQxGtdQAAwhgVOTw2/OaD+t2d+5XQ8aj2fBWrhQ+coqLtrYMdFuC1tq+Wqd3r+93G6pOt+uGJHu47GoYSH/lWrT87rPI/ddWRc+3NGCX8jtY6zGzINT/q9hl79dSULvr6k9b67W0HNGf5Ho27qIcq/xUV7PAAr9V3sarsgdNcn40Iy3H72P5+UDp+GGGKVesBsGHDBg0fPlzJycmyWCxatWpVMMPBLxh1+0GtXZ6gf7ycoJKdMVpwfxfV/duizBsOBTs0oEmMSIscbaNcm9PmXtdEf/tv2d86qIN3dAlShPC7Y/eR+7KFoKAm8pqaGvXr1095eXnBDAO/olWUU937HtEnG+NdY4Zh0acb49V74JEgRgY0XVRZnVLu/Epd7v5aHZ8qUeTBetd3ljqnOj5Von/dkixHWzpOCG1Bba0PGzZMw4YN83j/uro61dXVuT5XVVUFIiz8jC3BochWUsUB91+XHw+2Ukq3upMcBYSuum6tdeDOFDV0tqpVxVG1fa1cyQ/u1vePnSEjNlIJy/aq7ozWOnIOc+ItCa31EJCbmyu73e7aUlJSgh0SgDD07wE2HTm/rRq6xurf/eJVPiVNETUOtdlcqdbbKhX7ZbX+lZUc7DDhb4YfthAUVovdpk6dqpycHNfnqqoqknkzqDoUKcdRqW3Ho27j7Toc1Y8HwupXCDghZ5tINXS2Kqq8TpZSQ63K69X1li/d9un0xHeq7dlGZTNOD1KUwImF1b/CVqtVVqs12GGYztGGCO38f601YPBhbV7b2Gq0WAz1H1ytN5e2D3J0gO8stQ61Kq+X46Io1aTbdXhogtv3Xe79RoduStaRgbYgRQh/aKmt9bBK5AieN57toMnzS/XNZ61V9Gnj7WcxrZ36x4qEXz8YCDEJf9mrIwNtOtohWpE/Nqjda+VShFR9YVs5ba1OuMDtaIcoHe0UHYRo4Te8/Qxmtv7NdrK3d+ime8vUruNR7fkyVn8ek6aKg6zoRfiJPNTQuFL9sEMOWyvV9mitvQ91O+4WNCAcBPW3trq6Wrt27XJ9Li4u1vbt25WQkKDU1NQgRoYTeTO/g97M7xDsMACfHbinq1f7F6/oG6BI0Jxaams9qKvWt23bpgEDBmjAgAGSpJycHA0YMEDTp08PZlgAgJaomVet5+bm6txzz1V8fLw6deqkkSNHqqioyG2f2tpaZWdnq3379oqLi9Po0aNVXl7u1XWCmsgvueQSGYZx3LZ06dJghgUAgM/Wr1+v7OxsbdmyRevWrVNDQ4OuuOIK1dTUuPaZNGmSVq9erVdffVXr16/X3r17NWrUKK+uw4QQAMAUmru1vnbtWrfPS5cuVadOnVRYWKiLL75YlZWVWrJkiZYvX66hQ4dKkvLz89WrVy9t2bJF559/vkfXCasHwgAA0GROw/dNjc8w+e/tv584+ksqKyslSQkJjXf7FBYWqqGhQRkZGa59evbsqdTUVG3evNnjH4tEDgAwBz/NkaekpLg9ZTQ3N/dXL+10OjVx4kRdeOGFOuussyRJZWVlio6OVtu2bd32TUxMVFlZmcc/Fq11AAC8UFpaKpvtPw8H8uRBZdnZ2friiy+0adMmv8dDIgcAmIJFPs6R//S/NpvNLZH/mvHjx2vNmjXasGGDunT5z2txk5KSVF9fr4qKCreqvLy8XElJSR6fn9Y6AMAcmvl95IZhaPz48Vq5cqXee+89paWluX0/cOBARUVFqaCgwDVWVFSkkpISpaene3wdKnIAAAIgOztby5cv19/+9jfFx8e75r3tdrtiY2Nlt9s1btw45eTkKCEhQTabTRMmTFB6errHK9YlEjkAwCSa+/azRYsWSWp8Zsp/y8/P18033yxJmjdvniIiIjR69GjV1dUpMzNTCxcu9Oo6JHIAgDn4+k5xL481PGjFx8TEKC8vT3l5eU0MijlyAADCGhU5AMAULIYhiw+vIvXl2EAikQMAzMH50+bL8SGI1joAAGGMihwAYAq01gEACGfNvGq9uZDIAQDm0ISnsx13fAhijhwAgDBGRQ4AMIXmfrJbcyGRAwDMgdY6AAAINVTkAABTsDgbN1+OD0UkcgCAOdBaBwAAoYaKHABgDjwQBgCA8NVSH9FKax0AgDBGRQ4AMIcWutiNRA4AMAdDvr1TPDTzOIkcAGAOzJEDAICQQ0UOADAHQz7OkfstEr8ikQMAzKGFLnajtQ4AQBijIgcAmINTksXH40MQiRwAYAqsWgcAACGHihwAYA4tdLEbiRwAYA4tNJHTWgcAIIxRkQMAzIGKHACAMOb0w+aFDRs2aPjw4UpOTpbFYtGqVavcvjcMQ9OnT1fnzp0VGxurjIwM7dy50+sfi0QOADCFY7ef+bJ5o6amRv369VNeXt4Jv587d64WLFigxYsXa+vWrWrTpo0yMzNVW1vr1XVorQMA4IWqqiq3z1arVVar9bj9hg0bpmHDhp3wHIZhaP78+XrggQc0YsQISdKyZcuUmJioVatW6frrr/c4HipyAIA5HJsj92WTlJKSIrvd7tpyc3O9DqW4uFhlZWXKyMhwjdntdg0aNEibN2/26lxU5AAAc3AaksWHBWvOxmNLS0tls9lcwyeqxn9NWVmZJCkxMdFtPDEx0fWdp0jkAAB4wWazuSXyYKO1DgAwBz+11v0hKSlJklReXu42Xl5e7vrOUyRyAIBJ+JrE/ZfI09LSlJSUpIKCAtdYVVWVtm7dqvT0dK/ORWsdAIAAqK6u1q5du1yfi4uLtX37diUkJCg1NVUTJ07U7Nmz1b17d6WlpWnatGlKTk7WyJEjvboOiRwAYA7N/GS3bdu26dJLL3V9zsnJkSRlZWVp6dKluu+++1RTU6Pbb79dFRUVGjx4sNauXauYmBivrkMiBwCYg9PH9rjTu2MvueQSGb+Q/C0Wi2bNmqVZs2Y1PSYxRw4AQFijIgcAmIPhbNx8OT4EkcgBAObQQt9+RiIHAJhDM8+RNxfmyAEACGNU5AAAc6C1DgBAGDPkYyL3WyR+RWsdAIAwRkUOADAHWusAAIQxp1OSD/eCO0PzPnJa6wAAhDEqcgCAOdBaBwAgjLXQRE5rHQCAMEZFDgAwhxb6iFYSOQDAFAzDKcOHN5j5cmwgkcgBAOZgGL5V1cyRAwAAf6MiBwCYg+HjHHmIVuQkcgCAOTidksWHee4QnSOntQ4AQBijIgcAmAOtdQAAwpfhdMrwobUeqref0VoHACCMUZEDAMyB1joAAGHMaUiWlpfIaa0DABDGqMgBAOZgGJJ8uY88NCtyEjkAwBQMpyHDh9a6QSIHACCIDKd8q8i5/QwAANPJy8vTqaeeqpiYGA0aNEgfffSRX89PIgcAmILhNHzevPXyyy8rJydHM2bM0CeffKJ+/fopMzNT+/fv99vPRSIHAJiD4fR989ITTzyh2267TWPHjlXv3r21ePFitW7dWi+88ILffqywniM/tvDgqBp8uscfCGXOI7XBDgEIGOe/6yQ1z0IyX3PFUTVIkqqqqtzGrVarrFbrcfvX19ersLBQU6dOdY1FREQoIyNDmzdvbnogPxPWifzw4cOSpE36e5AjAQJo7N+CHQEQcIcPH5bdbg/IuaOjo5WUlKRNZb7niri4OKWkpLiNzZgxQw8++OBx+x48eFAOh0OJiYlu44mJifr66699juWYsE7kycnJKi0tVXx8vCwWS7DDMYWqqiqlpKSotLRUNpst2OEAfsXvd/MzDEOHDx9WcnJywK4RExOj4uJi1dfX+3wuwzCOyzcnqsabU1gn8oiICHXp0iXYYZiSzWbjHzq0WPx+N69AVeL/LSYmRjExMQG/zn/r0KGDIiMjVV5e7jZeXl6upKQkv12HxW4AAARAdHS0Bg4cqIKCAteY0+lUQUGB0tPT/XadsK7IAQAIZTk5OcrKytI555yj8847T/Pnz1dNTY3Gjh3rt2uQyOEVq9WqGTNmBH1OCAgEfr/hb9ddd50OHDig6dOnq6ysTP3799fatWuPWwDnC4sRqg+PBQAAv4o5cgAAwhiJHACAMEYiBwAgjJHIAQAIYyRyeCzQr+IDgmXDhg0aPny4kpOTZbFYtGrVqmCHBHiMRA6PNMer+IBgqampUb9+/ZSXlxfsUACvcfsZPDJo0CCde+65evrppyU1Pp0oJSVFEyZM0JQpU4IcHeA/FotFK1eu1MiRI4MdCuARKnL8qmOv4svIyHCNBeJVfAAA75HI8at+6VV8ZWVlQYoKACCRyAEACGskcvyq5noVHwDAeyRy/KrmehUfAMB7vP0MHmmOV/EBwVJdXa1du3a5PhcXF2v79u1KSEhQampqECMDfh23n8FjTz/9tB577DHXq/gWLFigQYMGBTsswGfvv/++Lr300uPGs7KytHTp0uYPCPACiRwAgDDGHDkAAGGMRA4AQBgjkQMAEMZI5AAAhDESOQAAYYxEDgBAGCORAwAQxkjkAACEMRI54KObb75ZI0eOdH2+5JJLNHHixGaP4/3335fFYlFFRcVJ97FYLFq1apXH53zwwQfVv39/n+L69ttvZbFYtH37dp/OA+DESORokW6++WZZLBZZLBZFR0erW7dumjVrlo4ePRrwa7/xxht66KGHPNrXk+QLAL+El6agxbryyiuVn5+vuro6/f3vf1d2draioqI0derU4/atr69XdHS0X66bkJDgl/MAgCeoyNFiWa1WJSUlqWvXrrrzzjuVkZGhN998U9J/2uFz5sxRcnKyevToIUkqLS3Vtddeq7Zt2yohIUEjRozQt99+6zqnw+FQTk6O2rZtq/bt2+u+++7Tz19X8PPWel1dne6//36lpKTIarWqW7duWrJkib799lvXizratWsni8Wim2++WVLja2Jzc3OVlpam2NhY9evXT6+99prbdf7+97/rjDPOUGxsrC699FK3OD11//3364wzzlDr1q112mmnadq0aWpoaDhuv2eeeUYpKSlq3bq1rr32WlVWVrp9//zzz6tXr16KiYlRz549tXDhQq9jAdA0JHKYRmxsrOrr612fCwoKVFRUpHXr1mnNmjVqaGhQZmam4uPjtXHjRn3wwQeKi4vTlVde6Tru8ccf19KlS/XCCy9o06ZNOnTokFauXPmL173pppv017/+VQsWLNCOHTv0zDPPKC4uTikpKXr99dclSUVFRdq3b5+efPJJSVJubq6WLVumxYsX68svv9SkSZN04403av369ZIa/+AYNWqUhg8fru3bt+vWW2/VlClTvP7/JD4+XkuXLtVXX32lJ598Us8995zmzZvnts+uXbv0yiuvaPXq1Vq7dq0+/fRT3XXXXa7vX3rpJU2fPl1z5szRjh079PDDD2vatGl68cUXvY4HQBMYQAuUlZVljBgxwjAMw3A6nca6desMq9VqTJ482fV9YmKiUVdX5zrmL3/5i9GjRw/D6XS6xurq6ozY2FjjnXfeMQzDMDp37mzMnTvX9X1DQ4PRpUsX17UMwzCGDBli3HPPPYZhGEZRUZEhyVi3bt0J4/znP/9pSDJ+/PFH11htba3RunVr48MPP3Tbd9y4ccYNN9xgGIZhTJ061ejdu7fb9/fff/9x5/o5ScbKlStP+v1jjz1mDBw40PV5xowZRmRkpPH999+7xt5++20jIiLC2Ldvn2EYhnH66acby5cvdzvPQw89ZKSnpxuGYRjFxcWGJOPTTz896XUBNB1z5Gix1qxZo7i4ODU0NMjpdOoPf/iDHnzwQdf3ffr0cZsX/+yzz7Rr1y7Fx8e7nae2tla7d+9WZWWl9u3b5/YO9latWumcc845rr1+zPbt2xUZGakhQ4Z4HPeuXbt05MgRXX755W7j9fX1GjBggCRpx44dx70LPj093eNrHPPyyy9rwYIF2r17t6qrq3X06FHZbDa3fVJTU3XKKae4XcfpdKqoqEjx8fHavXu3xo0bp9tuu821z9GjR2W3272OB4D3SORosS699FItWrRI0dHRSk5OVqtW7r/ubdq0cftcXV2tgQMH6qWXXjruXB07dmxSDLGxsV4fU11dLUl666233BKo1Djv7y+bN2/WmDFjNHPmTGVmZsput2vFihV6/PHHvY71ueeeO+4Pi8jISL/FCuDkSORosdq0aaNu3bp5vP/ZZ5+tl19+WZ06dTquKj2mc+fO2rp1qy6++GJJjZVnYWGhzj777BPu36dPHzmdTq1fv14ZGRnHfX+sI+BwOFxjvXv3ltVqVUlJyUkr+V69erkW7h2zZcuWX/8h/8uHH36orl276s9//rNr7Lvvvjtuv5KSEu3du1fJycmu60RERKhHjx5KTExUcnKy9uzZozFjxnh1fQD+wWI34CdjxoxRhw4dNGLECG3cuFHFxcV6//33dffdd+v777+XJN1zzz165JFHtGrVKn399de66667fvEe8FNPPVVZWVm65ZZbtGrVKtc5X3nlFUlS165dZbFYtGbNGh04cEDV1dWKj4/X5MmTNWnSJL344ovavXu3PvnkEz311FOuBWR33HGHdu7cqXvvvVdFRUVavny5li5d6tXP2717d5WUlGjFihXavXu3FixYcMKFezExMcrKytJnn32mjRs36u6779a1116rpKQkSdLMmTOVm5urBQsW6JtvvtHnn3+u/Px8PfHEE17FA6BpSOTAT1q3bq0NGzYoNTVVo0aNUq9evTRu3DjV1ta6KvQ//elP+uMf/6isrCylp6crPj5ev/3tb3/xvIsWLdLvfvc73XXXXerZs6duu+021dTUSJJOOeUUzZw5U1OmTFFiYqLGjx8vSXrooYc0bdo05ebmqlevXrryyiv11ltvKS0tTVLjvPXrr7+uVatWqV+/flq8eLEefvhhr37ea665RpMmTdL48ePVv39/ffjhh5o2bdpx+3Xr1k2jRo3SVVddpSuuuEJ9+/Z1u73s1ltv1fPPP6/8/Hz16dNHQ4YM0dKlS12xAggsi3GyVToAACDkUZEDABDGSOQAAIQxEjkAAGGMRA4AQBgjkQMAEMZI5AAAhDESOQAAYYxEDgBAGCORAwAQxkjkAACEMRI5AABh7P8DX2rXwTiFgWUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Run this cell without changes\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(estimator=DummyClassifier(strategy='constant', constant=1).fit(X_train, y_train),\n",
        "                                       X=X_test, y=y_test);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "56a6937dd02a56814c6ddbd870d2be88",
          "grade": false,
          "grade_id": "cell-6cc083aefe185bc9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "iLDHjjwR-Ol5"
      },
      "source": [
        "For each of the following questions, assume that a \"baseline\" metric means the metric we would find if our model always chose class 1.\n",
        "\n",
        "You can just use the numbers 89 and 54 in your answer; you don't need to use `y_test` directly.\n",
        "\n",
        "#### What is the baseline accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e755b181915a1928635263dbafbea91d",
          "grade": false,
          "grade_id": "cell-4fc8ecbde3cefea5",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "dwOfPf3N-Ol5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adca315-6b9c-4c02-ec1a-6daf8c440bcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6223776223776224"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Replace None with appropriate code\n",
        "# Given values\n",
        "total_instances = 89 + 54\n",
        "majority_class_instances = 89\n",
        "\n",
        "# Calculate baseline accuracy\n",
        "baseline_accuracy = majority_class_instances / total_instances\n",
        "\n",
        "\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()\n",
        "baseline_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "43b15a2ecf13d6232e02f8c930484716",
          "grade": true,
          "grade_id": "cell-d82e1145566cbde4",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1urWcKFC-Ol6"
      },
      "outputs": [],
      "source": [
        "# baseline_accuracy should be a number between 0 and 1\n",
        "assert 0.0 <= baseline_accuracy and baseline_accuracy <= 1.0\n",
        "\n",
        "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
        "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b3602d6ea1412f5a93bc2bb96dbc33c8",
          "grade": false,
          "grade_id": "cell-ce29090a1e7a50a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "rNtd8bJW-Ol8"
      },
      "source": [
        "#### What is the baseline recall?\n",
        "\n",
        "As a reminder, a \"negative\" prediction is represented as 0 (benign) and a \"positive\" prediction as 1 (malignant). So all baseline predictions will be either \"true positives\" (actually 1, predicted 1) or \"false positives\" (actually 0, predicted 1) and there will not be any \"true negatives\" or \"false negatives\" because this model always chooses 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1afa42887089cbba5fd6ac5ca740e5dc",
          "grade": false,
          "grade_id": "cell-bd2963c096bc719d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "z-m6r-r5-Ol9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72011384-287f-4c40-fa03-ac3cddd9e252"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Replace None with appropriate code\n",
        "# Given values\n",
        "true_positives = 89  # Since all predictions are positive, all are true positives\n",
        "\n",
        "# Calculate baseline recall\n",
        "baseline_recall = true_positives / true_positives\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()\n",
        "\n",
        "baseline_recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1af441fe5d623b8b83fd999a88aa6296",
          "grade": true,
          "grade_id": "cell-d1e42e6ab2e2dbbe",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "itQP-jaR-Ol-"
      },
      "outputs": [],
      "source": [
        "# baseline_recall should be a number between 0 and 1\n",
        "assert 0.0 <= baseline_recall and baseline_recall <= 1.0\n",
        "\n",
        "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
        "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3fb4fa3032fc6b6031784ba86ad30ad8",
          "grade": false,
          "grade_id": "cell-dba77045ab3d5734",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "oNhgMHuD-Ol_"
      },
      "source": [
        "#### What is the baseline precision?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1565f8e0ad75be5ca0b9f2a4b8ff37b7",
          "grade": false,
          "grade_id": "cell-ad278d44219e8d59",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "XSAtYItq-Ol_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bedc5277-b717-4a14-f5eb-21034f676367"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Replace None with appropriate code\n",
        "# Given values\n",
        "true_positives = 89  # Since all predictions are positive, all are true positives\n",
        "\n",
        "# Calculate baseline precision\n",
        "baseline_precision = true_positives / true_positives\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()\n",
        "\n",
        "baseline_precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cad6886e1fa5f31d5470160689d181fe",
          "grade": true,
          "grade_id": "cell-ef0982e7efdef257",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "yqD_C_9K-OmA"
      },
      "outputs": [],
      "source": [
        "# baseline_precision should be a number between 0 and 1\n",
        "assert 0.0 <= baseline_precision and baseline_precision <= 1.0\n",
        "\n",
        "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
        "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "39ed2200b2fe421b52cc606fa37ef63b",
          "grade": false,
          "grade_id": "cell-09a829b393083712",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eWUUcVPB-OmC"
      },
      "source": [
        "#### What is the baseline f1-score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4e4a3f036374389d18a8e63ead446de5",
          "grade": false,
          "grade_id": "cell-b2df160d3ab75209",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "yhBoIP65-OmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a80b88-53a5-4624-e977-fbb758b8a409"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Replace None with appropriate code\n",
        "baseline_f1 = 2 * (baseline_precision * baseline_recall) / (baseline_precision + baseline_recall)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()\n",
        "\n",
        "\n",
        "baseline_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "79b64c37103336ed2404a9857f99ce10",
          "grade": true,
          "grade_id": "cell-ffaf20b73f713bf7",
          "locked": true,
          "points": 0.5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WNOXA45r-OmE"
      },
      "outputs": [],
      "source": [
        "# baseline_f1 should be a number between 0 and 1\n",
        "assert 0.0 <= baseline_f1 and baseline_f1 <= 1.0\n",
        "\n",
        "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
        "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8b61e7f0a41a41b7d2fe29b1fc463af2",
          "grade": false,
          "grade_id": "cell-594415dfc9fb22d1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tNpBejYr-OmF"
      },
      "source": [
        "## 2. Instantiate and Fit a `LogisticRegression` Model\n",
        "\n",
        "Use the `LogisticRegression` model from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)). Specify a `random_state` of 42 but otherwise use default hyperparameters.\n",
        "\n",
        "Because logistic regression applies regularization by default, make sure you use the scaled training data to fit the model.\n",
        "\n",
        "Call this model `model`.\n",
        "\n",
        "We have also included code to display the confusion matrix on the training data; if the confusion matrix doesn't render, that indicates that something is incorrect about your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "179392aebf07a49006f10315bf84fa6c",
          "grade": false,
          "grade_id": "cell-b2952b81667870c7",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "qx7Mf6nI-OmG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "2abf5bec-0691-4178-b61d-c1988c6fc956"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Replace None with appropriate code\n",
        "\n",
        "# Import the relevant class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Instantiate the model\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Fit the model on the scaled data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6e20594b5b08f86873a250a8cacabeed",
          "grade": true,
          "grade_id": "cell-c43d403e0a8efb8c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "XESdCXSk-OmG"
      },
      "outputs": [],
      "source": [
        "# model should be a LogisticRegression\n",
        "assert type(model) == LogisticRegression\n",
        "\n",
        "# model should be fitted\n",
        "assert type(model.coef_) == np.ndarray\n",
        "\n",
        "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
        "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming you have your scaled training data X_train_scaled and labels y_train, replace them with your actual data\n",
        "# X_train_scaled = ...  # Your scaled training feature data\n",
        "# y_train = ...  # Your training labels\n",
        "\n",
        "# Instantiate Logistic Regression model with random_state=42\n",
        "model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Fit the model to the scaled training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions on the training data\n",
        "y_pred = model.predict(X_train_scaled)\n",
        "\n",
        "# Display confusion matrix\n",
        "cm = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Benign', 'Malignant'],\n",
        "            yticklabels=['Benign', 'Malignant'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix - Training Data')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "G6F6ZyFkD-Q9",
        "outputId": "f2a95aa7-c003-48ea-b360-6048bf072c78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suLyjYSo-OmH"
      },
      "source": [
        "### 3. Use Cross-Validation to Evaluate the Fitted Model\n",
        "\n",
        "Use `cross_val_score` from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)) to evaluate the expected accuracy of the fitted model, prior to using the test data.\n",
        "\n",
        "Use a `cv` of 3 and assign the result to `cv_scores`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5ffa59f1e3e77a84d9081358466ee41e",
          "grade": false,
          "grade_id": "cell-3b52c61d710a43d8",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Z3_LTOF8-OmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2137d4fc-29bf-4e49-8edb-c3ee1a11649b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.98591549, 0.97887324, 0.95070423])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Replace None with appropriate code\n",
        "\n",
        "# Import the relevant function\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=3)\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()\n",
        "\n",
        "cv_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0a2f9b6cf1478a800cf07104706ae923",
          "grade": true,
          "grade_id": "cell-10967fd0bba39816",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Mrob7ZRC-OmI"
      },
      "outputs": [],
      "source": [
        "# cv_scores should contain 3 scores. If it doesn't, double-check\n",
        "# the value passed in for cv\n",
        "assert len(cv_scores) == 3\n",
        "\n",
        "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
        "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ffb4d30bba69b8d5fa77c68d2d665b65",
          "grade": false,
          "grade_id": "cell-599a6362c8ef628f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "LS5UgxJ3-OmI"
      },
      "source": [
        "### 4. Compare Baseline and Fitted Model Scores\n",
        "\n",
        "Now, use functions from scikit-learn to compute the accuracy, recall, precision, and f1-score of the fitted model. We have prepared code that will print them out side-by-side with the baseline scores.\n",
        "\n",
        "Documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score), [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score), [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score), and [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score).\n",
        "\n",
        "This time, **use the test data to calculate each metric.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ff64061546476c28a9c26655cf9e2114",
          "grade": false,
          "grade_id": "cell-264adb30a8921fde",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "e9G5iL1r-OmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce044bad-16a3-464a-d994-c1f78a720f81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric          Model      Baseline\n",
            "------------------------------\n",
            "Accuracy        0.9790     0.6224\n",
            "Precision       0.9636     1.0000\n",
            "Recall          0.9815     1.0000\n",
            "F1 Score        0.9725     1.0000\n",
            "\n",
            "Accuracy\n",
            "Baseline: 0.622 Fitted Model: 0.979\n",
            "Recall\n",
            "Baseline: 1.000 Fitted Model: 0.981\n",
            "Precision\n",
            "Baseline: 1.000 Fitted Model: 0.964\n",
            "F1 Score\n",
            "Baseline: 1.000 Fitted Model: 0.972\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Replace None with appropriate code\n",
        "y_pred_test = model.predict(X_test_scaled)\n",
        "model_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "model_recall = recall_score(y_test, y_pred_test)\n",
        "model_precision = precision_score(y_test, y_pred_test)\n",
        "model_f1 = f1_score(y_test, y_pred_test)\n",
        "# YOUR CODE HERE\n",
        "#raise NotImplementedError()\n",
        "\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"{'Metric':<15} {'Model':<10} {'Baseline'}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"{'Accuracy':<15} {model_accuracy:<10.4f} {'0.6224'}\")\n",
        "print(f\"{'Precision':<15} {model_precision:<10.4f} {'1.0000'}\")\n",
        "print(f\"{'Recall':<15} {model_recall:<10.4f} {'1.0000'}\")\n",
        "print(f\"{'F1 Score':<15} {model_f1:<10.4f} {'1.0000'}\")\n",
        "\n",
        "\n",
        "print(f\"\"\"\n",
        "Accuracy\n",
        "Baseline: {baseline_accuracy:1.3f} Fitted Model: {model_accuracy:1.3f}\n",
        "Recall\n",
        "Baseline: {baseline_recall:1.3f} Fitted Model: {model_recall:1.3f}\n",
        "Precision\n",
        "Baseline: {baseline_precision:1.3f} Fitted Model: {model_precision:1.3f}\n",
        "F1 Score\n",
        "Baseline: {baseline_f1:1.3f} Fitted Model: {model_f1:1.3f}\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "09dcd60da46d529519135e8892d32bb7",
          "grade": true,
          "grade_id": "cell-c91e7c7e516f8d41",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "CiJVw7IN-OmK"
      },
      "outputs": [],
      "source": [
        "# all scores should be values between 0 and 1\n",
        "assert 0.0 <= model_accuracy and model_accuracy <= 1.0\n",
        "assert 0.0 <= model_recall and model_recall <= 1.0\n",
        "assert 0.0 <= model_precision and model_precision <= 1.0\n",
        "assert 0.0 <= model_f1 and model_f1 <= 1.0\n",
        "\n",
        "# PUT ALL WORK FOR THE ABOVE QUESTION ABOVE THIS CELL\n",
        "# THIS UNALTERABLE CELL CONTAINS HIDDEN TESTS"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "9c94107dbb6f31e400bb19858c9768759ef7c8600537d1d879eb7d5b058e9ee3"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}